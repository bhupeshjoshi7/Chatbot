{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Journal of Physics: Conference Series\\nPAPER • OPEN ACCESS\\nVideo Content-Based Advertisement Recommendation System using\\nClassification Technique of Machine Learning\\nTo cite this article: R C Konapure and L M R J Lobo 2021 J. Phys.: Conf. Ser. 1854 012025\\n\\xa0\\nView the article online  for updates and enhancements. \\n \\nThis content was downloaded from IP address 45.114.159.106 on 11/05/2021 at 09:36', metadata={'source': 'data\\\\doc.pdf', 'page': 0}),\n",
       " Document(page_content='Content from this work may be used under the terms of the Creative Commons Attribution 3.0 licence. Any further distribution\\nof this work must maintain attribution to the author(s) and the title of the work, journal citation and DOI.\\nPublished under licence by IOP Publishing LtdFEST 2020\\nJournal of Physics: Conference Series 1854 (2021) 012025IOP Publishing\\ndoi:10.1088/1742-6596/1854/1/012025\\n1 \\n   \\n \\n \\nVideo Content-Based Advertisement Recommendation System', metadata={'source': 'data\\\\doc.pdf', 'page': 1}),\n",
       " Document(page_content='using Classification Technique of Machine Learning \\nR C Konapure1 and Dr L M R J Lobo2 \\n1PG Student, Department of Computer Science and Engineering, Walchand Institute \\nof Technology, P.A.H. Solapur University, Solapur, Maharashtra, India \\n2Professor, Department of Computer Science and Engineering, Walchand Institute of  \\nTechnology, P.A.H. Solapur University, Solapur, Maharashtra, India \\n1konapurer@gmail.com, 2headitwit@gmail.com', metadata={'source': 'data\\\\doc.pdf', 'page': 1}),\n",
       " Document(page_content='Abstract  Content-based advertising is a method by which we advertise on a video media based \\non a relevant topic assigned to the video. In digital advertising, the advertisements shown to a \\nuser is based on the user’s behaviour on the internet. Streaming platforms are then used to \\ntarget audience based on parameters like user’s geo-location, interests, watch history, age, etc.', metadata={'source': 'data\\\\doc.pdf', 'page': 1}),\n",
       " Document(page_content='In most cases, the advertisements shown are not relevant; an undesired impact is created. Content-based advertising helps to convey the message with increased efficiency and simultaneously optimizes its conversion rate. In this proposed system we take the video metadata as input and apply the NLP techniques for text classification which categories the video and assigns a relevant advertisement to it. The second module takes the video as an input. Thereafter the video is converted into N', metadata={'source': 'data\\\\doc.pdf', 'page': 1}),\n",
       " Document(page_content='is converted into N individual frames to tackle the video classification as an image classification problem. In this proposed system we train a Convolutional Neural Network to identify the topic of the video on an image dataset and', metadata={'source': 'data\\\\doc.pdf', 'page': 1}),\n",
       " Document(page_content=\"compare its performance with a pre-trained model. We create the image dataset by \\ndownloading images from the internet. We also create a video advertisement's dataset by web \\nscrapping. This proposed system makes sure that the user is shown the advertisement in \\nreference to the video. This increases probability of the user visiting the client's website. \\n \\n1.  Introduction \\nPresent day digital-age advertising is more complex than ever. Advertisers today have a chance to\", metadata={'source': 'data\\\\doc.pdf', 'page': 1}),\n",
       " Document(page_content=\"meet consumers at every stage of their online browsing process. However, it takes a deep level of \\ninsight into conversion behaviour and easy access to real-time digital decision-making tools to know \\nwhen, how and to what extent it is indeed needed to communicate with a customer. Today's modern \\nadvertisers must rely on technology to decide the best way to boost their advertising return on \\ninvestment (ROI) and meet their target clients. Recommendation systems have been implemented with\", metadata={'source': 'data\\\\doc.pdf', 'page': 1}),\n",
       " Document(page_content='the emergence of streaming sites like YouTube, Netflix and many other such web services. \\nRecommendation systems are inevitable in our everyday online browsing, from e-commerce (to \\nrecommend a similar product) to online ads (based on a user interests).', metadata={'source': 'data\\\\doc.pdf', 'page': 1}),\n",
       " Document(page_content='FEST 2020\\nJournal of Physics: Conference Series 1854 (2021) 012025IOP Publishing\\ndoi:10.1088/1742-6596/1854/1/012025\\n2 \\n   \\n \\n \\n1.1 Motivation \\nThe social advertising market is ever growing, having an outreach to customers of all the age groups \\nand remote areas. The reason behind the use of social networking sites as a platform for advertising is', metadata={'source': 'data\\\\doc.pdf', 'page': 2}),\n",
       " Document(page_content=\"to suggest a potential customer who is interested in a product to get relevant information resulting in a high conversion ratio. An advertiser is motivated to use a social networking site as standardised \\nplatform. The 2018 State of Digital Advertising Study from Adobe Digital Insights reveals that social \\nmedia advertisements had drawn three times more non-consumers to the retailer's website by the end\", metadata={'source': 'data\\\\doc.pdf', 'page': 2}),\n",
       " Document(page_content=\"of 2017 than current customers. Today’s people concentrate more on online facilities for advertisement \\nwhich make their life easier.  As this survey report brings to light that people connect to these sites to a \\ngreater extent which further helps the advertiser.  The video accounts for 80% of web traffic over the \\ncourse of 2020, according to the expert's estimate. YouTube is well known publically in the digital\", metadata={'source': 'data\\\\doc.pdf', 'page': 2}),\n",
       " Document(page_content='market involving video presentations. The advertisements occupy less memory space and are optimised. The user base is almost as high as that of Facebook, with approximately over 2 billion monthly active users. The difference between the YouTube and Facebook models is that for extended sessions, every single person watches videos. This is exactly what is expected. There was a gain for \\nmotivation due to the following:', metadata={'source': 'data\\\\doc.pdf', 'page': 2}),\n",
       " Document(page_content='1. The proposed system helps to provide an accurate advertisement during the video which \\nconsequently increases the actual conversion ratio of the targeted audience. \\n2. As we proposed to provide the advertisement in reference to the video content, users will not be \\ndispleased by irrelevant advertisements. \\n 1.2 Objective  \\nPaid digital advertisement has shown great growth continually on various platforms. Most marketers', metadata={'source': 'data\\\\doc.pdf', 'page': 2}),\n",
       " Document(page_content='realize the importance of fulfilling a customer’s requirement, thus they use these platforms to reach the \\ncore audience. The methodologies adapted in the algorithms are based on video content. This automatically decreases the load on a server. A reflection is seen on the sorted data which reduces unnecessary searches, thus saving access time. Thrust technologies like machine learning and pattern \\nmatching are adopted to generate correct customer through the metadata of advertisements in the', metadata={'source': 'data\\\\doc.pdf', 'page': 2}),\n",
       " Document(page_content='videos. This ensures that an advertisement will be shown only to relevant users who will benefit from \\nthe system.  \\n \\n \\n2.  Literature Review \\nTo understand the problem the reviews of the previous studies in this domain need to be visited. The \\nmethodology followed to identify the unexplored part of the field of study under consideration is \\nbased on extensions provided in this literature. \\n  \\nOnur Sevli et.al. [2] focused his study on recommendation systems w.r.t advertisements which', metadata={'source': 'data\\\\doc.pdf', 'page': 2}),\n",
       " Document(page_content='suggested the use of  a Twitter platform to show the advertisement to the correct user. For this task, \\npost shares, news by a user community in Turkish, natural language processing and big data analysis \\ntechniques were used to distribute ads only to those users who need the product. This developed system described the fields of personal interest by identifying the word patterns most widely used in sharing. A web service was developed to present content to consumers, marked by a range of', metadata={'source': 'data\\\\doc.pdf', 'page': 2}),\n",
       " Document(page_content='advertisement database categories and keywords and ideally tailored to user preferences. Abu Bashar \\net al. [3] explored the experience of consumers and advertisers in the state of Punjab on a social \\nnetworking platform. This study resulted in the suggestion that the metrics for the efficacy of social \\nmedia should be interesting, insightful, interactive and accurate. Social marketing sites need to be alert', metadata={'source': 'data\\\\doc.pdf', 'page': 2}),\n",
       " Document(page_content=\"to consumers' shifting tastes and expectations. This study indicated that advertising encourages market\", metadata={'source': 'data\\\\doc.pdf', 'page': 2}),\n",
       " Document(page_content='FEST 2020\\nJournal of Physics: Conference Series 1854 (2021) 012025IOP Publishing\\ndoi:10.1088/1742-6596/1854/1/012025\\n3 \\n   \\n \\n \\ncompetitiveness that increases the availability of customers with higher quality goods. \\nThirumalaisamy Ragunathana et al. [9] suggested a model of customer behaviour based on posting a \\nrelevant advertisement after a customer’s visit to a website. The proposed model analyses the', metadata={'source': 'data\\\\doc.pdf', 'page': 3}),\n",
       " Document(page_content='mechanism and activities in which individuals browse, pick, purchase, use, review and dispose \\nproducts and services in order to fulfil their needs and desires. The author used Hadoop to handle huge \\ndata of the customer behavioural model used to display relevant advertisements on the website.  \\nA multi-label video identification system was proposed by Kwangsoo et. al. [10] on the \\nYouTube data. The growth of video data is rapid because of developments in digital technology.', metadata={'source': 'data\\\\doc.pdf', 'page': 3}),\n",
       " Document(page_content='Therefore, the need for techniques to automatically classify visual content is increasing. The YouTube-8M dataset along with NetVLAD and NetFV models as well as the Huber loss function was used to check the needs for video classification problems. Mariana Arantes et. al. [4] addressed the use of YouTube video advertising. YouTube is the most popular streaming site that uses advertisements to raise billions of dollars each year. On YouTube, individuals can create and upload their content after', metadata={'source': 'data\\\\doc.pdf', 'page': 3}),\n",
       " Document(page_content='their content after they hit a certain number of views and subscribers the channel can be monetized. This research', metadata={'source': 'data\\\\doc.pdf', 'page': 3}),\n",
       " Document(page_content='provided insights into how ads generate revenue, the popularity of video ads, user behaviour when \\nthey are exposed to advertisements, and how content creators can generate revenue as a person via \\ntheir YouTube channel. This research focused primarily on user behaviour, with an emphasis on video', metadata={'source': 'data\\\\doc.pdf', 'page': 3}),\n",
       " Document(page_content='content. Dardis et al. [11] experimented in order to understand the influence of banner advertising and video ads on brand recall. Within two distinct game environments, they conducted the study: games developed for advertising purposes (called advergames) and non-branded games. Among their results, they found that in non-branded games, video ads are better than banner ads and also that the role of', metadata={'source': 'data\\\\doc.pdf', 'page': 3}),\n",
       " Document(page_content='mid-roll video ads was more prominent. Thus, looking into the work done by previous researchers it \\nwas concluded that each researcher focused on a very particular video advertisement scenario. This \\ndeveloped motivation to study video advertisements with a broader view. \\n 3. Data Collection \\nData collection is an important step to be followed in order to apply machine learning algorithms. \\nRelevant answers to specific questions in the data collection process can determine results from an', metadata={'source': 'data\\\\doc.pdf', 'page': 3}),\n",
       " Document(page_content='established system. These are inherently based on collecting and estimating information on targeted \\nvariables. A collection of data for experimentation was extracted from scratch and a unique database is \\ncreated.  3.1 Text Data', metadata={'source': 'data\\\\doc.pdf', 'page': 3}),\n",
       " Document(page_content='To perform the text classification, YouTube videos metadata using YouTube API v3 is collected. This dataset consists of fields: video id, title, description, hashtags, duration and upload details etc. A total of more than 10,000 video metadata is collected and divided into six categories. This dataset items \\ncontain a lot of noise which proves to be challenging. Before building a classification model we', metadata={'source': 'data\\\\doc.pdf', 'page': 3}),\n",
       " Document(page_content='should perform data pre-processing. Natural Language Toolkit (NL TK) package of NLP does the job \\nof pre-processing efficiently. It consists of data pre-processing tools required for text classification. \\n3.2 Image Data \\nFor the video classification model a Convolutional Neural Network is trained to identify the sport in \\nthe video. Image data from Google images of 22 categories of sports (badminton, baseball, cricket,', metadata={'source': 'data\\\\doc.pdf', 'page': 3}),\n",
       " Document(page_content='football, etc.) is collected. Each sport category has around 700 – 800 images. The same dataset is used to create a video classification model with Keras and deep learning. A comparison was done between the developed model and the inception v3 model.    3.3 Advertisement data The main objective of the proposed system is to recommend a video advertisement to the video on a \\nstreaming platform based on its content. In order to achieve this various advertisements in the video', metadata={'source': 'data\\\\doc.pdf', 'page': 3}),\n",
       " Document(page_content='format are collected and metadata of these are extracted and stored in a database. The advertisement \\nvideo data consists of information regarding video URL, video id, title, description etc.', metadata={'source': 'data\\\\doc.pdf', 'page': 3}),\n",
       " Document(page_content='FEST 2020\\nJournal of Physics: Conference Series 1854 (2021) 012025IOP Publishing\\ndoi:10.1088/1742-6596/1854/1/012025\\n4 \\n   \\n \\n \\n \\n4. Methodology \\nThe use of the advertisements depended on how relevant and suitable they would be to a specific user.  In this paper, the content match scenario is used and two classification models are proposed. One \\nmodel for text data and the other for video data.', metadata={'source': 'data\\\\doc.pdf', 'page': 4}),\n",
       " Document(page_content='4.1 The Proposed Recommender Algorithm Video content pre-dominates the working of the recommender algorithm. Keeping in mind relevance \\nto a user based on the content in a video is of prime importance. This reflects on a user giving a better \\nresponse to the system. The proposed algorithm solves the problem of recommending more related \\nadvertisements and provides an opportunity to generate a higher user response and satisfaction thus', metadata={'source': 'data\\\\doc.pdf', 'page': 4}),\n",
       " Document(page_content='resulting in increasing business value [5]. The steps in the algorithms are as follows:  4.1.1 Text classification. The text classification model of the proposed system is developed as shown \\nin Figure 1.   \\n \\n \\n \\n \\n \\n   \\nThe first step in data pre-processing is to handle the missing data. Since missing values are', metadata={'source': 'data\\\\doc.pdf', 'page': 4}),\n",
       " Document(page_content='supposed to be text data in the proposed system there is no way to substitute them, the only option is to remove them. Following this on the remaining data natural language processing text cleaning \\ntechniques are performed to generate clean and required data [5]. This approach involves converting to \\nlowercase, removing numerical values and punctuation, removing extra white spaces, tokenizing into \\nwords, lemmatization, removing non-alphabetical words and stop words.', metadata={'source': 'data\\\\doc.pdf', 'page': 4}),\n",
       " Document(page_content='Data extraction and data analysis have to be performed. Data cleaning, transformation, and \\ndata modelling comprise analysis to discover useful information and to support decision-making. The \\ndata extraction process consists of retrieval of information from the available data sources for further', metadata={'source': 'data\\\\doc.pdf', 'page': 4}),\n",
       " Document(page_content='data processing [5].  Data modelling is used to define and analyse the data needed to support the machine learning model and store it into a database to perform required operations on it. In data modelling, the processed dataset is divided into a training dataset and a test dataset. In the proposed system we form a training dataset with the features extracted using the Term Frequency Inverse Document Frequency (TFIDF) vectorization method [5].', metadata={'source': 'data\\\\doc.pdf', 'page': 4}),\n",
       " Document(page_content='Classification label is a process of producing labels i.e. output from the classifier model. The \\nlabels are related to the content. \\n 4.1.2. Video Classification. The video classification model of the proposed system is developed as \\nshown in Figure 2. \\n      \\n Classificati\\non Labels Gathering \\nData \\n Data \\nCleaning & \\nPre-\\nprocessing  Data \\nAnalyzing \\n& \\nExtraction  Modelling \\nand \\nTraining \\n \\nFigure 1: An overview of the text classification', metadata={'source': 'data\\\\doc.pdf', 'page': 4}),\n",
       " Document(page_content='FEST 2020\\nJournal of Physics: Conference Series 1854 (2021) 012025IOP Publishing\\ndoi:10.1088/1742-6596/1854/1/012025\\n5 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n   \\n \\n \\n \\n \\n \\n \\n \\nThe model is trained on the training dataset using a supervised learning method. The training \\ndataset consists of an input and the correspondin g output, which is commonly denoted as the target \\nvariable. The current model runs with the traini ng dataset and produces a result, which is then', metadata={'source': 'data\\\\doc.pdf', 'page': 5}),\n",
       " Document(page_content='compared with the target variable, for each input in the training dataset. Based on the result of the \\ncomparison and the specific learning algorithm being used the parameters of the model are adjusted. \\nIn the prediction stage, a test dataset is taken; this dataset is independent of the training \\ndataset. The prediction phase works similarly to the training phase with the difference that in the', metadata={'source': 'data\\\\doc.pdf', 'page': 5}),\n",
       " Document(page_content='training set pre-defined labels to the machine learni ng classification algorithm are fed and a classifier \\nmodel is built. In prediction extracted features to the classifier model are fed which in turn produces \\nlabels for classification. The test dataset is a set of examples used to check the performance of a \\nproducing classifier model and results are achieved in terms of labels for classification.', metadata={'source': 'data\\\\doc.pdf', 'page': 5}),\n",
       " Document(page_content='To summarize the whole process videos are first converted into a series of images which are \\npassed through CNN. The prediction from the CNN is obtained and a list for all the frames is \\ndetermined. The average of these frames is calcul ated and the labels are chosen having highest \\nprobability. Frames are then labeled and outputs are written to the disk. \\n \\nIn order to develop a simple transfer learning with an Inception v3 architecture model, the', metadata={'source': 'data\\\\doc.pdf', 'page': 5}),\n",
       " Document(page_content='same data is used. On ImageNet images, the Inception v3 architecture model is trained; a new top layer that can identify other image classes is trained. For each image, the top layer receives a 2048-\\ndimensional vector as the input. On top of this representation, a softmax layer is applied. If the \\nsoftmax layer includes N labels, this refers to the parameters of the learning N + 2048*N model \\ncorresponding to the biases and weights learned. \\n \\n \\nInput \\nInput \\nFeature \\nExtractor \\nFeature', metadata={'source': 'data\\\\doc.pdf', 'page': 5}),\n",
       " Document(page_content='Extractor \\nFeature \\nExtractor \\nFeatures\\nFeatures \\nMachine \\nlearning \\nalgorithm \\nClassifier \\nmodel \\nLabel  \\nClassification Labels \\n(b) Prediction  \\n(a) Training \\nFigure 2: An overview of the video classification', metadata={'source': 'data\\\\doc.pdf', 'page': 5}),\n",
       " Document(page_content='FEST 2020\\nJournal of Physics: Conference Series 1854 (2021) 012025IOP Publishing\\ndoi:10.1088/1742-6596/1854/1/012025\\n6 \\n   \\n \\n \\n5. Results and Discussion \\n5.1 Text Classification \\nThe testing starts with the data of six categories Travel Blogs, Science and Technology, Food, \\nManufacturing, History, Art, and Music. The classifier used in the experiment is the LSTM classifier.  \\n \\nTable 1: Confusion Matrix \\n \\nart and \\nmusic  food  History  manufact\\nuring  science and \\ntechnology travel', metadata={'source': 'data\\\\doc.pdf', 'page': 6}),\n",
       " Document(page_content='technology travel  \\nart and music 394 2 3 3 0 1 \\nfood 5 425 0 1 6 1 \\nhistory 6 0 411 0 2 2 \\nmanufacturing 2 0 0 395 0 0 \\nscience and \\ntechnology  5 1 2 4 391 0 \\ntravel  7 6 0 0 0 425 \\n \\n \\nThe confusion matrix is built by LSTM Classifier as shown in Table 1. Looking vertically at \\nthe value of a class in the confusion matrix, one can see the instances of a category as assigned by a classifier. For example, looking at the above confusion matrix shows that the LSTM classifier has', metadata={'source': 'data\\\\doc.pdf', 'page': 6}),\n",
       " Document(page_content='correctly classified 394 instances of art and music as the Health class (True Positives, TP) while 25 \\ninstances are False Positives (FP). \\n \\nTable 2: text classification accuracy by class \\n precision recall f1 - score support \\nart and music  0.94 0.98 0.96 403 \\nfood 0.98 0.97 0.97 438 \\nhistory  0.99 0.98 0.98 421 \\nmanufacturing  0.98 0.99 0.99 397 \\nscience and \\ntechnology  0.98 0.97 0.98 403 \\ntravel  0.99 0.97 0.97 438 \\n     \\naccuracy    0.98 2500 \\nmacro avg  0.98 0.98 0.98 2500', metadata={'source': 'data\\\\doc.pdf', 'page': 6}),\n",
       " Document(page_content='weighted avg  0.98 0.98 0.98 2500  \\n \\nConsidering precision, recall, f1-score, support it can be seen that the LSTM classifier \\nconsistently gives better performance. For the six categories, the Advertisement Recommendation system dynamically recommended the relevant advertisements up to 98%. \\n \\n5.2 Video Classification  \\nDue to the high cost of processing time and processing power required by most of the classifiers, and', metadata={'source': 'data\\\\doc.pdf', 'page': 6}),\n",
       " Document(page_content='the number of iterations to produce the best from the classifiers the experiment was conducted in \\nstages.', metadata={'source': 'data\\\\doc.pdf', 'page': 6}),\n",
       " Document(page_content='FEST 2020\\nJournal of Physics: Conference Series 1854 (2021) 012025IOP Publishing\\ndoi:10.1088/1742-6596/1854/1/012025\\n7 \\n \\n \\n \\n \\n \\n                   \\n          Figure 3: Output of CNN model                               Figure 4: Output of the pre-trained model                                 \\nFigure 3 shows the output of the video classification model with a classification label. Using this \\nclassification label as a keyword we retrieve the advertisement’s related to tennis.', metadata={'source': 'data\\\\doc.pdf', 'page': 7}),\n",
       " Document(page_content='Table 3: video classification accuracy by class \\n precision recall f1 - score support \\nfootball  0.88 0.95 0.92 196 \\ntennis  0.90 0.91 0.90 179 \\nweight_lifting  0.97 0.84 0.90 143 \\n     \\naccuracy    0.91 518 \\nmacro avg  0.92 0.90 0.91 518 \\nweighted avg  0.91 0.91 0.91 518 \\n \\nIn Table 3 considering precision, recall, f1-score, support it can be seen that the video classifier \\nconsistently gives better performance with 91 % accuracy. We compared the above results with the', metadata={'source': 'data\\\\doc.pdf', 'page': 7}),\n",
       " Document(page_content=\"pre-trained model's results. Table 4 below shows the labels with their calculated score of pre-trained \\nmodel. \\n \\nTable 4: Pre-trained model results comparison \\ntennis (score \\n0.09849) fencing (score \\n0.05321) kabaddi (score - \\n0.03406) wrestling (score \\n0.01801) \\ntable tennis \\n(score 0.09332) hockey (score \\n0.04715) baseball (score - \\n0.03229) basketball \\n(score 0.01588) \\ngymnastics \\n(score 0.09309)  chess (score \\n0.04510)  shooting (score \\n0.03163)  ice hockey \\n(score 0.01523)  \\nwwe (score\", metadata={'source': 'data\\\\doc.pdf', 'page': 7}),\n",
       " Document(page_content='wwe (score \\n0.09008) football (score \\n0.04218) volleyball \\n(score 0.02345) motogp (score. \\n0.01435) \\nformula1 (score \\n0.07433) swimming \\n(score 0.03859) weight lifting \\n(score 0.02197)  \\nboxing (score \\n0.06044) cricket (score - \\n0.03547) badminton \\n(score- 0.02169)', metadata={'source': 'data\\\\doc.pdf', 'page': 7}),\n",
       " Document(page_content='FEST 2020\\nJournal of Physics: Conference Series 1854 (2021) 012025IOP Publishing\\ndoi:10.1088/1742-6596/1854/1/012025\\n8 \\n \\n \\n \\n \\n \\n5.3 Recommendation System Results \\nFigure 5 shows the advertisement generated from the keyword identified by CNN model. The keyword \\nis then retrieved from the advertisement dataset by matching title, description of the source video. Only matched data will return more relevant videos. In the proposed system the CNN model identifies', metadata={'source': 'data\\\\doc.pdf', 'page': 8}),\n",
       " Document(page_content='the sport as tennis. Using this keyword this system retrieves the video shown is Figure 5.  \\n \\n \\nFigure 5 : Advertisement shown related to tennis \\n \\n \\n \\n \\n6. Conclusion \\nIn the proposed system with the text classification model advertisement placement on a video has \\nachieved an accuracy of 98% with LSTM classifier which was better than Naïve Bayes which gave an \\naccuracy of 96% and Adaboost Classifier which gave an accuracy of 86% for the same input data. In', metadata={'source': 'data\\\\doc.pdf', 'page': 8}),\n",
       " Document(page_content='video classification the results of the developed system have been compared to the pre-trained model. \\nKeeping the dataset constant the developed model gave an accuracy of 91% which is calculated on', metadata={'source': 'data\\\\doc.pdf', 'page': 8}),\n",
       " Document(page_content='average score of the labels for a fixed number of frames. However for pre-trained model the accuracy score has been calculated for individual frames. Though they have reached an accuracy of 98% this does not consider the average scores of labels. This accuracy may fall down after achieving all the labels once all the frames are available for analysis.  \\nWith the proposed system, advertisers are ultimately benefited from the outcome of', metadata={'source': 'data\\\\doc.pdf', 'page': 8}),\n",
       " Document(page_content='this research effort. They are able to provide their consumers with more effective \\nadvertisement campaigns  while generating more revenue for both parties. This model uses \\ncontextual data to publish advertisements more efficiently increasing user response to \\nadvertising through better placement, duration, and format of advertisements to the targeted \\naudience. This system provides accurate and more related advertisements and information to', metadata={'source': 'data\\\\doc.pdf', 'page': 8}),\n",
       " Document(page_content='users more purposefully. This analysis can also be used to improve other aspects of the online \\nadvertising business facilitating them to gain a competitive advantage in the growing and \\ncompetitive market. The suite of algorithms that have been applied resulted in successful and \\nacceptable quality predictions.', metadata={'source': 'data\\\\doc.pdf', 'page': 8}),\n",
       " Document(page_content='FEST 2020\\nJournal of Physics: Conference Series 1854 (2021) 012025IOP Publishing\\ndoi:10.1088/1742-6596/1854/1/012025\\n9 \\n   \\n \\n \\n7. References \\n[1] Virda S, Yu-Qian Z,  Achmad Nizar H, Puspa I and Bo H. International Journal of Information \\nManagement 48  2019 Exploring the psychological mechanisms from personalized \\nadvertisements to urge to buy impulsively on social media. 96–107. \\n[2] Onur S, Ecir K. International Journal of Tehnički vjesnik  2015 Advertising recommendation', metadata={'source': 'data\\\\doc.pdf', 'page': 9}),\n",
       " Document(page_content='system based on dynamic data analysis on Turkish speaking twitter users ISSN 1330-3651 \\n(Print), ISSN 1848-6339 (Online)  Retrieved from https://hrcak.srce.hr/file/265215. \\n[3] Abu B, Irshad A. ELK Asia Pacific Journal of Marketing & Retail Management  Effectiveness \\nof Social media as a marketing tool: An empirical study. \\n[4] Mariana A, Flavio F and Jussara M. The Journal of Web Science  Volume 4 2018 Towards \\nUnderstanding the Consumption of Video-Ads on YouTube. 1–19', metadata={'source': 'data\\\\doc.pdf', 'page': 9}),\n",
       " Document(page_content='[5] Rushikesh K, Dr. L.M.R.J. Lobo. MAT Journals  7 Feb. 2020 Text Data Analysis for \\nAdvertisement Recommendation System Using Multi-label Classification of Machine Learning. \\n[6] Sree Vani M. International Journal of Advanced Research in Computer and Communication \\nEngineering  Vol. 5, Issue 2, February 2016 A Recommender System for Online Advertising. \\n599-604 \\n[7] Nhan N-T, Dana M, Kinda K, David R, Flavian V, Elena Simona L, Steven M, Dominique Q.', metadata={'source': 'data\\\\doc.pdf', 'page': 9}),\n",
       " Document(page_content='arXiv:1909.04190v1 [cs.IR]   9 Sep 2019 Recommendation System-based Upper Confidence \\nBound for Online Advertising. \\n[8] Missi Hikmatyar and Ruuhwan. Journal of Physics: Conference Series 1477 032024  2020 Book \\nRecommendation System Development Using User-Based Collaborative Filtering. \\n[9] Thirumalaisamy R, Sudheer K, Battulab V. International Journal of Computer Science \\nProcedia 50 Advertisement Posting based on Consumer Behavior. 329 – 334', metadata={'source': 'data\\\\doc.pdf', 'page': 9}),\n",
       " Document(page_content='[10] Kwangsoo S, Junhyeong J, Seungbin L, Boyoung L, Minsoo J, Jongho N. IEEE Conference on \\nComputer Vision and Pattern Recognition  Approach for video classification with multi-label \\non YouTube-8M dataset 5297-5307. \\n[11] Dardis, F. E., M. Schmierbach, B. Sherrick, F. Waddell, J. Aviles, S. Kumble, and E. Journal of \\nInteractive Advertising Bailey  Adver-Where? Comparing the Effectiveness of Banner Ads \\nand Video Ads in Online Video Games. 1–14', metadata={'source': 'data\\\\doc.pdf', 'page': 9}),\n",
       " Document(page_content='[12] Arantes, M., F. Figueiredo, and J. M. Almeida. WebSci  Understanding video-ad consumption on \\nYouTube: a measurement study on user behaviour, popularity, and content properties. \\n[13] Li, H., and H.-Y. Lo. Journal of Advertising  44(3) Do You Recognize Its Brand? The \\nEffectiveness of Online In-Stream Video Advertisements. 208–218', metadata={'source': 'data\\\\doc.pdf', 'page': 9})]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500 , chunk_overlap=20)\n",
    "    text_chunks= text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "text_chunks =text_split(extracted_data)\n",
    "text_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bhupesh\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.data.index.Index at 0x2b0c12f9790>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"chatbot\"  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x2b0c14537f0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore  \n",
    "docsearch = PineconeVectorStore.from_texts(\n",
    "        [t.page_content for t in text_chunks],\n",
    "        index_name=index_name,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "\n",
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result [Document(page_content='arXiv:1909.04190v1 [cs.IR]   9 Sep 2019 Recommendation System-based Upper Confidence \\nBound for Online Advertising. \\n[8] Missi Hikmatyar and Ruuhwan. Journal of Physics: Conference Series 1477 032024  2020 Book \\nRecommendation System Development Using User-Based Collaborative Filtering. \\n[9] Thirumalaisamy R, Sudheer K, Battulab V. International Journal of Computer Science \\nProcedia 50 Advertisement Posting based on Consumer Behavior. 329 – 334'), Document(page_content='arXiv:1909.04190v1 [cs.IR]   9 Sep 2019 Recommendation System-based Upper Confidence \\nBound for Online Advertising. \\n[8] Missi Hikmatyar and Ruuhwan. Journal of Physics: Conference Series 1477 032024  2020 Book \\nRecommendation System Development Using User-Based Collaborative Filtering. \\n[9] Thirumalaisamy R, Sudheer K, Battulab V. International Journal of Computer Science \\nProcedia 50 Advertisement Posting based on Consumer Behavior. 329 – 334')]\n"
     ]
    }
   ],
   "source": [
    "docsearch=PineconeVectorStore.from_existing_index(index_name, embeddings)\n",
    "\n",
    "\n",
    "\n",
    "docs=docsearch.similarity_search(query, k=2)\n",
    "\n",
    "print(\"Result\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = docsearch.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# from langchain.chains import RetrievalQA\n",
    "\n",
    "# qa_chain = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,  # Your language model instance\n",
    "#     chain_type=\"stuff\",  # The chain type (could be \"map_reduce\", \"stuff\", etc.)\n",
    "#     retriever=retriever,  # The retriever instance (e.g., from Pinecone or other vector databases)\n",
    "#     return_source_documents=True,  # Set to True if you want to return the source documents\n",
    "#     chain_type_kwargs=chain_type_kwargs  # Additional chain-specific keyword arguments\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "retriever = docsearch.as_retriever(search_kwargs={\"k\": 2})\n",
    "chain = load_qa_chain(llm,chain_type=\"stuff\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " System in this context refers to a well-established framework or structure for collecting, organizing, and analyzing data. The text mentions that the established system is inherently based on collecting and estimating information on targeted variables, which suggests that it is a pre-existing methodology for gathering and analyzing data. Therefore, the answer to the question \"What is system?\" in this context is a well-defined framework or structure for data collection and analysis.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is system?\"\n",
    "docs = retriever.get_relevant_documents(query)  # Get relevant documents from the retriever\n",
    "result = chain.run(input_documents=docs, question=query)  # Run the QA chain with the retrieved documents\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input=input(f\"Input Prompt:\")\n",
    "    result=qa({\"query\": user_input})\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
